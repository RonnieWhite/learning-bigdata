netcat命令：
    windows: nc -l -p 9999
    linux: nc -l -k 9999

批处理使用DataSet API
流处理使用DataStream API

大数据处理的流程：
    MapReduce: input -> map(reduce) -> output
    Storm: input -> Spout/Bolt -> output
    Spark: input -> transformation/action -> output
    Flink: input -> transformation/sink -> output

Flink编程模型：
    1) 获取执行环境
    2) 获取数据
    3) transformation
    4) sink
    5) 触发执行

course03下的代码展示了指定key的字段表达式和key选择器三种方式，分别是：
    1) Tupe指定
    2) 字段表达式指定
    3) key选择器

指定转换函数：
    1) 直接new一个FlatMapFunction并重载flatMap方法，text.flatMap(new FlatMapFunction<String, WC>() {}
    2) 定义一个类实现FlatMapFunction接口并重载flatMap方法（myFlatMapFunction为实现类），text.flatMap(new myFlatMapFunction())
    3） jdk8的匿名函数方法
    4) Rich functions text.flatMap(new RichFlatMapFunction<String, WC>() {}

flink支持的数据类型：
    1) Java Tuples and Scala Case Classes
    2) Java POJOs -- 类必须为public， 必须有无参构造 必须有getter和setter方法
    3) Primitive Types -- 基本数据类型
    4) Regular Classes -- 通用类型
    5) Values
    6) Hadoop Writables
    7) Special Types

DataSet API编程：
    1) 数据加载 fromCollection readTextFile 解决了自己造值、csv文件读取、递归读取、以及压缩文件读取
    2) transformation：
       map filter mapPartition(生产中用得多)
       first flatMap distinct join(leftOuterJoin rightOuterJoin fullOuterJoin)
       cross
    3) 计数器
    4) 分布式缓存
    5) 广播变量

DataStream API编程：
    1) Flink自定义数据源：StreamExecutionEnvironment.addSource(sourceFunction)
        -- 实现SourceFunction以创建一个无并行的数据源
        -- 实现ParallelSourceFunction接口
        -- 继承RichParallelSourceFunction以创建一个能够并行的数据源
    2) 算子：除DataSet里所讲的之外，重点关注map和filter的连用, union, split+select
    4) Flink自定义Sink：
        -- 自定义类继承RichSinkFunction<T> T为要写入对象的类型
        -- 重写方法：
           -- open/close 生命周期方法
           -- invoke 每条记录执行一次

Time Windows编程:
    1) 处理时间类型
        -- 事件时间 Event Time
        -- 摄取时间 Ingestion Time
        -- 处理时间 Processing Time
    2) 设置处理时间类型
       env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    3) 窗口分配器：定义如何将数据分配给窗口
       每个传入的数据被分配到一个或多个窗口
       分类：
           -- 滚动窗口 tumbling windows 常用
                    固定大小，不会重叠
           -- 滑动窗口 sliding windows 常用
                    固定大小，可能会重叠
           -- 会话窗口 session windows
           -- 全局窗口 global windows
           通过继承WindowAssigner, 可自定义窗口

       窗口方法：
           reduce -- 流式，有一个计算一个
           process -- 批量，等本批次数据到齐后计算一次

Connectors:
    1) hdfs connector
    2) kafka connector

Flink运行:
    1) 启动服务：bin/start-cluster.sh
    2) 运行任务：./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000

ON YARN是企业级用得最多的方式
   Required
     -n,--container <arg>   Number of YARN container to allocate (=Number of Task Managers)
   Optional
     -D <arg>                        Dynamic properties
     -d,--detached                   Start detached
     -id,--applicationId <arg>       Attach to running YARN session
     -j,--jar <arg>                  Path to Flink jar file
     -jm,--jobManagerMemory <arg>    Memory for JobManager Container [in MB] JobManager的内存
     -n,--container <arg>            Number of YARN container to allocate (=Number of Task Managers) TaskManagers的个数
     -nm,--name <arg>                Set a custom name for the application on YARN
     -q,--query                      Display available YARN resources (memory, cores)
     -qu,--queue <arg>               Specify YARN queue.
     -s,--slots <arg>                Number of slots per TaskManager
     -st,--streaming                 Start Flink in streaming mode
     -t,--ship <arg>                 Ship files in the specified directory (t for transfer)
     -tm,--taskManagerMemory <arg>   Memory per TaskManager Container [in MB] Task Managers的内存
     -z,--zookeeperNamespace <arg>   Namespace to create the Zookeeper sub-paths for high availability mode

     1) 启动Hadoop集群：
          到hadoop主目录下：
             sbin/start-all.sh
     2) 启动flink集群：
          到flink主目录下：
             bin/start-cluster.sh
     3) 启动flink的yarn-session.sh
          到flink主目录下(参数详解如上)：
             bin/yarn-session.sh -n 1 -jm 1024 -tm 1024
     4) 跑一个示例作业：
          -- 先下载一个文本文档，然后传到hdfs
          -- 执行作业
             到flink主目录下：
                 ./bin/flink run ./examples/batch/WordCount.jar -input hdfs://myspark:9000/LICENSE-2.0.txt -output hdfs://myspark:9000/wordcount-result.txt

    在YARN上启动Flink集群
        ./bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar

    启动flink的scala shell
        bin/start-scala-shell.sh local

Flink监控及调优：
    1) HistoryServer
    2) REST API
    3) Metrics
    4) 常用优化

